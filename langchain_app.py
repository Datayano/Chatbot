import streamlit as st
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field
from typing import List, Optional
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Define the output schema using Pydantic
class RecipeRecommendation(BaseModel):
    recipe_name: str = Field(description="Nom de la recette")
    cooking_time: str = Field(description="Temps de cuisson estim√©")
    ingredients: List[str] = Field(description="Liste des ingr√©dients principaux")
    instructions: Optional[str] = Field(description="Instructions de cuisson br√®ves")
    difficulty: str = Field(description="Niveau de difficult√© (Facile, Moyen, Difficile)")
    
    class Config:
        schema_extra = {
            "example": {
                "recipe_name": "Spaghetti Carbonara",
                "cooking_time": "20 minutes",
                "ingredients": ["spaghetti", "≈ìufs", "fromage pecorino", "guanciale", "poivre noir"],
                "instructions": "Cuire les p√¢tes, pr√©parer la sauce avec les ≈ìufs et le fromage, m√©langer avec le guanciale croustillant",
                "difficulty": "Moyen"
            }
        }



# Initialize embedding model
@st.cache_resource
def get_embeddings():
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEY not found in environment variables")
    return OpenAIEmbeddings(
        model="text-embedding-3-small"  # Using the smaller, more cost-effective model
    )

# Initialize LLM
@st.cache_resource
def get_llm():
    if not os.getenv("GROQ_API_KEY"):
        raise ValueError("GROQ_API_KEY not found in environment variables")
    return ChatGroq(
        groq_api_key=os.getenv("GROQ_API_KEY"),
        model_name="mixtral-8x7b-32768",
        temperature=0.7,
    )

# Load existing vectorstore
@st.cache_resource
def get_vectorstore():
    embeddings = get_embeddings()
    
    # Check if vectorstore exists
    if not os.path.exists("./chroma_db"):
        raise ValueError("Vectorstore not found. Please run generate_vectorstore.py first!")
    
    # Load the existing vectorstore
    vectorstore = Chroma(
        persist_directory="./chroma_db",
        embedding_function=embeddings
    )
    
    return vectorstore

# Create the conversational chain
def get_conversation_chain(vectorstore):
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    # Create output parser
    parser = PydanticOutputParser(pydantic_object=RecipeRecommendation)
    
    # Create custom prompt template
    template = """Tu es un assistant culinaire sympathique et comp√©tent. Utilise les √©l√©ments de contexte suivants pour 
    fournir des recommandations de recettes et des conseils de cuisine utiles. Si tu recommandes une recette, formate-la selon 
    le sch√©ma JSON sp√©cifi√©. Pr√™te attention aux m√©tadonn√©es qui incluent le temps de cuisson et la taille des portions.
    R√©ponds toujours en fran√ßais.

    Contexte: {context}
    
    Historique de conversation: {chat_history}
    
    Humain: {question}
    
    Assistant: Je vais t'aider avec √ßa. 
    {format_instructions}
    """
    
    prompt = PromptTemplate(
        template=template,
        input_variables=["context", "chat_history", "question"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=get_llm(),
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        combine_docs_chain_kwargs={"prompt": prompt}
    )
    
    return conversation_chain

def main():
    st.set_page_config(
        page_title="Assistant Culinaire",
        page_icon="üç≥",
        layout="wide"
    )
    
    st.title("üßë‚Äçüç≥ Assistant Culinaire LangChain")
    st.markdown("""
    <style>
    .recipe-card {
        padding: 20px;
        border-radius: 10px;
        background-color: #f0f7ff;
        margin: 10px 0;
        border: 1px solid #cce0ff;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .ingredient-list {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 5px;
        border: 1px solid #e0e0e0;
    }
    .recipe-header {
        color: #2c5282;
        font-size: 1.5em;
        margin-bottom: 15px;
    }
    .recipe-metadata {
        display: inline-block;
        margin: 5px 10px;
        padding: 5px 10px;
        background-color: #ffffff;
        border-radius: 15px;
        border: 1px solid #e0e0e0;
    }
    .instructions-box {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 5px;
        border: 1px solid #e0e0e0;
        margin-top: 10px;
    }
    .chat-message {
        padding: 10px;
        margin: 5px 0;
        border-radius: 5px;
    }
    .user-message {
        background-color: #e3f2fd;
        margin-left: 20%;
        margin-right: 5%;
    }
    .assistant-message {
        background-color: #f5f5f5;
        margin-left: 5%;
        margin-right: 20%;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Initialize session state
    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # Initialize components
    try:
        vectorstore = get_vectorstore()
        if st.session_state.conversation is None:
            st.session_state.conversation = get_conversation_chain(vectorstore)
        
        # Chat interface
        st.markdown("""
        ### üëã Bienvenue sur votre Assistant Culinaire IA !
        Je peux vous aider √† trouver des recettes, donner des conseils de cuisine et r√©pondre √† vos questions culinaires.
        Essayez de me demander par exemple :
        - "Je veux cuisiner quelque chose avec du poulet et des l√©gumes"
        - "Quelle est une recette rapide de p√¢tes ?"
        - "Donne-moi une recette pour un d√Æner v√©g√©tarien"
        """)
        
        # User input
        user_input = st.text_input("Que souhaitez-vous cuisiner aujourd'hui ?", key="user_input", 
                                 placeholder="Posez-moi n'importe quelle question sur la cuisine ou les recettes !")
        
        if user_input:
            with st.spinner('Recherche de la recette parfaite...'):
                # Get response from conversation chain
                response = st.session_state.conversation({
                    "question": user_input,
                    "chat_history": st.session_state.chat_history
                })
                
                # Add to chat history
                st.session_state.chat_history.append((user_input, response["answer"]))
            
            # Display current conversation
            st.markdown("### üìù Derni√®res Recommandations")
            
            try:
                # Try to parse the response as a RecipeRecommendation
                recipe = RecipeRecommendation.parse_raw(response["answer"])
                
                # Display recipe in a nice card format
                with st.container():
                    st.markdown(f"""
                    <div class="recipe-card">
                        <div class="recipe-header">üçΩÔ∏è {recipe.recipe_name}</div>
                        <div class="recipe-metadata">‚è±Ô∏è {recipe.cooking_time}</div>
                        <div class="recipe-metadata">üìä {recipe.difficulty}</div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("### ü•ò Ingr√©dients")
                        with st.container():
                            st.markdown('<div class="ingredient-list">', unsafe_allow_html=True)
                            for ingredient in recipe.ingredients:
                                st.markdown(f"‚Ä¢ {ingredient}")
                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown("### üìù Instructions")
                        if recipe.instructions:
                            st.markdown('<div class="instructions-box">', unsafe_allow_html=True)
                            st.write(recipe.instructions)
                            st.markdown('</div>', unsafe_allow_html=True)
            
            except:
                # If parsing fails, display the raw response with markdown formatting
                st.markdown('<div class="chat-message assistant-message">', unsafe_allow_html=True)
                st.markdown(response["answer"])
                st.markdown('</div>', unsafe_allow_html=True)
            
            # Display chat history in a collapsible section
            with st.expander("üí¨ Voir l'historique de conversation", expanded=False):
                for user_msg, ai_msg in st.session_state.chat_history:
                    st.markdown('<div class="chat-message user-message">', unsafe_allow_html=True)
                    st.markdown(f"**Vous:** {user_msg}")
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    st.markdown('<div class="chat-message assistant-message">', unsafe_allow_html=True)
                    st.markdown(f"**Assistant:** {ai_msg}")
                    st.markdown('</div>', unsafe_allow_html=True)
    
    except Exception as e:
        st.error("‚ö†Ô∏è Erreur de Configuration")
        st.error(f"Une erreur s'est produite : {str(e)}")
        st.markdown("""
        Veuillez v√©rifier :
        1. Que toutes les cl√©s API requises sont d√©finies dans le fichier `.env`
        2. Que le vectorstore a √©t√© g√©n√©r√© en utilisant `generate_vectorstore.py`
        3. Que les d√©pendances n√©cessaires sont install√©es
        """)

if __name__ == "__main__":
    main()
